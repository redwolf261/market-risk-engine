{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72f96d56",
   "metadata": {},
   "source": [
    "# Monte Carlo Market Risk Engine\n",
    "## Professional Risk Analysis Report\n",
    "\n",
    "**Author:** Rivan Avinash Shetty  \n",
    "**Model Type:** 1-Day Trading Desk Risk Model  \n",
    "**Engine:** Correlated Monte Carlo Simulation (100,000 paths)  \n",
    "**Extensions:** Student-t Heavy-Tailed MC, Backtesting, Stress Testing  \n",
    "\n",
    "---\n",
    "\n",
    "## Executive Summary\n",
    "\n",
    "This report presents a comprehensive market risk analysis for a diversified 5-asset portfolio spanning equities, fixed income, and commodities. The risk engine implements **four** complementary VaR methodologies — Historical Simulation, Parametric (Variance-Covariance), Gaussian Monte Carlo, and **Student-t Monte Carlo** — validated through rolling-window backtesting and stress-tested under extreme volatility and correlation scenarios.\n",
    "\n",
    "**Key Findings:**\n",
    "- Portfolio composition: SPY (30%), QQQ (20%), JPM (15%), TLT (20%), GLD (15%)\n",
    "- 99% 1-day VaR and Expected Shortfall computed across all four models\n",
    "- **Student-t MC** captures heavy tails and produces higher VaR/ES than the Gaussian MC — more realistic for extreme events\n",
    "- Backtesting validates model adequacy via Kupiec proportion-of-failures test\n",
    "- Stress testing quantifies risk amplification under volatility doubling and correlation breakdown\n",
    "\n",
    "### Regulatory Context\n",
    "\n",
    "Under **Basel III / FRTB**, the regulatory standard shifted from VaR to **Expected Shortfall (ES)** because VaR does not capture the severity of tail losses. This engine computes both metrics, enabling a direct comparison of their behaviour across different distributional assumptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc9ee82",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e829cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.portfolio import (\n",
    "    fetch_data, load_data, compute_log_returns,\n",
    "    define_weights, compute_portfolio_returns,\n",
    "    get_portfolio_summary, DEFAULT_TICKERS,\n",
    ")\n",
    "from src.statistics import (\n",
    "    get_all_statistics, compute_rolling_volatility,\n",
    ")\n",
    "from src.risk_metrics import historical_risk_metrics, parametric_risk_metrics\n",
    "from src.monte_carlo import run_monte_carlo_engine\n",
    "from src.student_t_mc import fit_degrees_of_freedom, run_student_t_mc_engine\n",
    "from src.backtesting import run_full_backtest\n",
    "from src.stress_testing import full_stress_analysis\n",
    "\n",
    "# Configuration\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'raw_prices.csv'\n",
    "NUM_SIMULATIONS = 100_000\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "print('Environment ready.')\n",
    "print(f'Project root: {PROJECT_ROOT}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0599b572",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Data Acquisition & Portfolio Construction\n",
    "\n",
    "### 2.1 Asset Selection\n",
    "\n",
    "| Asset | Ticker | Weight | Rationale |\n",
    "|-------|--------|--------|-----------|\n",
    "| S&P 500 ETF | SPY | 30% | Broad market exposure |\n",
    "| Nasdaq 100 ETF | QQQ | 20% | High-beta tech sector |\n",
    "| JPMorgan Chase | JPM | 15% | Financial sector |\n",
    "| 20+ Year Treasury | TLT | 20% | Duration / interest rate risk |\n",
    "| Gold ETF | GLD | 15% | Safe-haven diversifier |\n",
    "\n",
    "Cross-asset covariance structure is critical — this portfolio includes assets with low or negative correlations to capture meaningful diversification effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e2a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load or fetch price data\n",
    "if DATA_PATH.exists():\n",
    "    prices = load_data(str(DATA_PATH))\n",
    "    print(f'Loaded cached data: {prices.shape[0]} observations')\n",
    "else:\n",
    "    prices = fetch_data(save_path=str(DATA_PATH))\n",
    "    print(f'Fetched fresh data: {prices.shape[0]} observations')\n",
    "\n",
    "print(f'\\nDate range: {prices.index[0].date()} to {prices.index[-1].date()}')\n",
    "print(f'Assets: {list(prices.columns)}')\n",
    "prices.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db570de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute log returns and portfolio\n",
    "# Pass prices.columns (alphabetical from yfinance) so weights are correctly aligned\n",
    "weights = define_weights(tickers=list(prices.columns))\n",
    "log_returns = compute_log_returns(prices)\n",
    "port_returns = compute_portfolio_returns(log_returns, weights)\n",
    "\n",
    "# Portfolio summary\n",
    "summary = get_portfolio_summary(prices, weights)\n",
    "\n",
    "print('Weight–Asset Alignment:')\n",
    "for t, w in zip(prices.columns, weights):\n",
    "    print(f'  {t}: {w:.2f}')\n",
    "print()\n",
    "print('Portfolio Summary')\n",
    "print('=' * 45)\n",
    "for k, v in summary.items():\n",
    "    print(f'  {k:.<35} {v:>10.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a86857",
   "metadata": {},
   "source": [
    "### 2.2 Return Distributions\n",
    "\n",
    "Log returns are computed as:\n",
    "\n",
    "$$r_t = \\ln\\left(\\frac{P_t}{P_{t-1}}\\right)$$\n",
    "\n",
    "The portfolio return at each time step is:\n",
    "\n",
    "$$R_p = \\mathbf{w}^T \\mathbf{R}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ad47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize individual asset return distributions\n",
    "fig, axes = plt.subplots(2, 3, figsize=(16, 9))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, col in enumerate(log_returns.columns):\n",
    "    axes[i].hist(log_returns[col], bins=80, density=True, alpha=0.7,\n",
    "                 color='steelblue', edgecolor='none')\n",
    "    axes[i].set_title(f'{col} Daily Returns', fontsize=12, fontweight='bold')\n",
    "    axes[i].axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "    axes[i].set_xlabel('Log Return')\n",
    "\n",
    "# Portfolio returns in last subplot\n",
    "axes[-1].hist(port_returns, bins=80, density=True, alpha=0.7,\n",
    "              color='darkred', edgecolor='none')\n",
    "axes[-1].set_title('Portfolio Return', fontsize=12, fontweight='bold')\n",
    "axes[-1].axvline(0, color='black', linewidth=0.8, linestyle='--')\n",
    "axes[-1].set_xlabel('Log Return')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'return_distributions.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4c6fec",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Statistical Estimation\n",
    "\n",
    "### Key Estimators\n",
    "\n",
    "**Mean vector:**\n",
    "$$\\boldsymbol{\\mu} = E[\\mathbf{r}]$$\n",
    "\n",
    "**Covariance matrix:**\n",
    "$$\\Sigma = E\\left[(\\mathbf{r} - \\boldsymbol{\\mu})(\\mathbf{r} - \\boldsymbol{\\mu})^T\\right]$$\n",
    "\n",
    "**Portfolio variance:**\n",
    "$$\\sigma_p^2 = \\mathbf{w}^T \\Sigma \\mathbf{w}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a622e5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all statistics\n",
    "mu, cov, corr, port_stats = get_all_statistics(log_returns, weights)\n",
    "\n",
    "print('Daily Mean Return Vector')\n",
    "print('=' * 35)\n",
    "for i, ticker in enumerate(prices.columns):\n",
    "    print(f'  {ticker}: {mu[i]:>12.6f}')\n",
    "\n",
    "print(f'\\nPortfolio Statistics')\n",
    "print('=' * 35)\n",
    "for k, v in port_stats.items():\n",
    "    print(f'  {k:.<30} {v:>12.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dd1c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariance matrix\n",
    "print('Covariance Matrix (×10⁴ for readability):\\n')\n",
    "cov_df = pd.DataFrame(cov * 1e4, index=prices.columns, columns=prices.columns)\n",
    "print(cov_df.to_string(float_format=lambda x: f'{x:.4f}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9082724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "fig, ax = plt.subplots(figsize=(9, 7))\n",
    "mask = np.triu(np.ones_like(corr, dtype=bool), k=1)\n",
    "sns.heatmap(corr, mask=mask, annot=True, fmt='.3f', cmap='RdYlBu_r',\n",
    "            center=0, vmin=-1, vmax=1, square=True, linewidths=0.5,\n",
    "            xticklabels=prices.columns, yticklabels=prices.columns, ax=ax,\n",
    "            cbar_kws={'shrink': 0.8, 'label': 'Correlation'})\n",
    "ax.set_title('Asset Correlation Matrix', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'correlation_heatmap.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2b6fa",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Risk Model Results\n",
    "\n",
    "Four VaR methodologies are implemented and compared:\n",
    "\n",
    "### Model 1: Historical Simulation\n",
    "- Distribution-free — uses empirical quantiles of realized losses\n",
    "- No parametric assumptions, but backward-looking\n",
    "\n",
    "### Model 2: Parametric (Variance-Covariance)\n",
    "- Assumes Gaussian returns: $\\text{VaR}_\\alpha = z_\\alpha \\cdot \\sigma_p - \\mu_p$\n",
    "- Fast, but underestimates tail risk\n",
    "\n",
    "### Model 3: Gaussian Monte Carlo (Flagship)\n",
    "- Cholesky decomposition: $\\Sigma = \\mathbf{L}\\mathbf{L}^T$\n",
    "- Correlated simulation: $\\mathbf{R} = \\boldsymbol{\\mu} + \\mathbf{L}\\mathbf{Z}$, where $\\mathbf{Z} \\sim N(\\mathbf{0}, \\mathbf{I})$\n",
    "- 100,000 paths — full P&L distribution\n",
    "\n",
    "### Model 4: Student-t Monte Carlo (Heavy-Tailed Extension)\n",
    "- Replaces Gaussian innovations with Student-t: $Z \\sim t(\\nu)$\n",
    "- Degrees of freedom $\\nu$ fitted via MLE on historical returns\n",
    "- Captures fat tails: extreme moves are more probable than under Gaussian\n",
    "- When $\\nu \\to \\infty$, converges to the Gaussian MC (nested model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94299e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical VaR\n",
    "hist_metrics = historical_risk_metrics(port_returns)\n",
    "\n",
    "# Parametric VaR\n",
    "param_metrics = parametric_risk_metrics(\n",
    "    port_stats['portfolio_mean'],\n",
    "    port_stats['portfolio_std'],\n",
    ")\n",
    "\n",
    "# Gaussian Monte Carlo VaR\n",
    "mc_results = run_monte_carlo_engine(\n",
    "    mu, cov, weights, NUM_SIMULATIONS, RANDOM_SEED\n",
    ")\n",
    "mc_metrics = {\n",
    "    'mc_var_95': mc_results['var_95'],\n",
    "    'mc_var_99': mc_results['var_99'],\n",
    "    'mc_es_95': mc_results['es_95'],\n",
    "    'mc_es_99': mc_results['es_99'],\n",
    "}\n",
    "\n",
    "# Student-t Monte Carlo VaR\n",
    "print('Fitting Student-t degrees of freedom via MLE...')\n",
    "df_t, loc_t, scale_t = fit_degrees_of_freedom(port_returns.values)\n",
    "print(f'  Fitted ν = {df_t:.2f}  (lower ν → heavier tails)')\n",
    "print(f'  Location = {loc_t:.6f}, Scale = {scale_t:.6f}')\n",
    "\n",
    "t_results = run_student_t_mc_engine(\n",
    "    mu, cov, weights, df_t, NUM_SIMULATIONS, RANDOM_SEED\n",
    ")\n",
    "t_metrics = {\n",
    "    't_var_95': t_results['var_95'],\n",
    "    't_var_99': t_results['var_99'],\n",
    "    't_es_95': t_results['es_95'],\n",
    "    't_es_99': t_results['es_99'],\n",
    "}\n",
    "\n",
    "print(f'\\nAll 4 models computed ({NUM_SIMULATIONS:,} simulations for MC engines).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389553ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison table — all 4 models\n",
    "comparison = pd.DataFrame({\n",
    "    'Model': ['Historical', 'Parametric (Gaussian)',\n",
    "              'Monte Carlo (Gaussian)', f'Monte Carlo (Student-t, ν={df_t:.1f})'],\n",
    "    '95% VaR': [\n",
    "        hist_metrics['hist_var_95'],\n",
    "        param_metrics['param_var_95'],\n",
    "        mc_metrics['mc_var_95'],\n",
    "        t_metrics['t_var_95'],\n",
    "    ],\n",
    "    '99% VaR': [\n",
    "        hist_metrics['hist_var_99'],\n",
    "        param_metrics['param_var_99'],\n",
    "        mc_metrics['mc_var_99'],\n",
    "        t_metrics['t_var_99'],\n",
    "    ],\n",
    "    '95% ES': [\n",
    "        hist_metrics['hist_es_95'],\n",
    "        param_metrics['param_es_95'],\n",
    "        mc_metrics['mc_es_95'],\n",
    "        t_metrics['t_es_95'],\n",
    "    ],\n",
    "    '99% ES': [\n",
    "        hist_metrics['hist_es_99'],\n",
    "        param_metrics['param_es_99'],\n",
    "        mc_metrics['mc_es_99'],\n",
    "        t_metrics['t_es_99'],\n",
    "    ],\n",
    "})\n",
    "\n",
    "comparison.set_index('Model', inplace=True)\n",
    "\n",
    "# Format as percentages for display\n",
    "styled = comparison.style.format('{:.4%}').set_caption(\n",
    "    'VaR & Expected Shortfall Comparison (1-Day Horizon)'\n",
    ").set_properties(**{'text-align': 'right'})\n",
    "styled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb32434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monte Carlo P&L distribution\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "pnl = mc_results['portfolio_pnl']\n",
    "ax.hist(pnl, bins=300, density=True, color='steelblue', alpha=0.7, edgecolor='none',\n",
    "        label='Simulated P&L')\n",
    "\n",
    "ax.axvline(-mc_results['var_95'], color='#ff7f0e', lw=2, ls='--',\n",
    "           label=f\"95% VaR = {mc_results['var_95']:.4%}\")\n",
    "ax.axvline(-mc_results['var_99'], color='#d62728', lw=2, ls='--',\n",
    "           label=f\"99% VaR = {mc_results['var_99']:.4%}\")\n",
    "ax.axvline(-mc_results['es_99'], color='#9467bd', lw=2, ls=':',\n",
    "           label=f\"99% ES = {mc_results['es_99']:.4%}\")\n",
    "\n",
    "import matplotlib.ticker as mtick\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xlabel('Portfolio Return', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Monte Carlo Simulated 1-Day P&L Distribution', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'mc_pnl_distribution.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3de22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left-tail zoom\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "\n",
    "cutoff = np.percentile(pnl, 10)\n",
    "tail_data = pnl[pnl <= cutoff]\n",
    "\n",
    "ax.hist(tail_data, bins=150, density=True, color='steelblue', alpha=0.7,\n",
    "        edgecolor='none', label='Left Tail P&L')\n",
    "ax.axvline(-mc_results['var_95'], color='#ff7f0e', lw=2, ls='--',\n",
    "           label=f\"95% VaR = {mc_results['var_95']:.4%}\")\n",
    "ax.axvline(-mc_results['var_99'], color='#d62728', lw=2, ls='--',\n",
    "           label=f\"99% VaR = {mc_results['var_99']:.4%}\")\n",
    "ax.axvline(-mc_results['es_99'], color='#9467bd', lw=2, ls=':',\n",
    "           label=f\"99% ES = {mc_results['es_99']:.4%}\")\n",
    "ax.axvspan(tail_data.min(), -mc_results['var_99'], alpha=0.15, color='#d62728',\n",
    "           label='Tail Loss Region')\n",
    "\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xlabel('Portfolio Return', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Left Tail Zoom — VaR & Expected Shortfall', fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'left_tail_zoom.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a54f6",
   "metadata": {},
   "source": [
    "### 4.1 Gaussian vs Student-t — Fat Tail Impact\n",
    "\n",
    "The key insight: **the Student-t distribution assigns more probability mass to extreme events** (tail returns beyond 3σ). This is critical because:\n",
    "\n",
    "1. Real financial returns exhibit **excess kurtosis** — extreme moves happen more often than a Normal predicts\n",
    "2. The Gaussian assumption causes VaR to **systematically underestimate** tail risk (confirmed by our backtesting below)\n",
    "3. The fitted degrees of freedom $\\nu$ directly quantify *how far from Gaussian* the returns are — lower $\\nu$ means fatter tails\n",
    "\n",
    "The chart below overlays both distributions side-by-side. Notice how the Student-t (red) has more mass in the far left tail, producing higher VaR and especially higher ES."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e350806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian vs Student-t distribution overlay\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "g_pnl = mc_results['portfolio_pnl']\n",
    "t_pnl = t_results['portfolio_pnl']\n",
    "\n",
    "# Left panel: Full distribution overlay\n",
    "ax = axes[0]\n",
    "ax.hist(g_pnl, bins=250, density=True, alpha=0.55, color='steelblue',\n",
    "        edgecolor='none', label='Gaussian MC')\n",
    "ax.hist(t_pnl, bins=250, density=True, alpha=0.55, color='#d62728',\n",
    "        edgecolor='none', label=f'Student-t MC (ν={df_t:.1f})')\n",
    "ax.axvline(-mc_results['var_99'], color='steelblue', lw=2, ls='--',\n",
    "           label=f\"Gauss 99% VaR = {mc_results['var_99']:.4%}\")\n",
    "ax.axvline(-t_results['var_99'], color='#d62728', lw=2, ls='--',\n",
    "           label=f\"t 99% VaR = {t_results['var_99']:.4%}\")\n",
    "ax.set_xlabel('Portfolio Return', fontsize=12)\n",
    "ax.set_ylabel('Density', fontsize=12)\n",
    "ax.set_title('Full P&L Distribution — Gaussian vs Student-t', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=9.5, loc='upper right')\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "# Right panel: Left-tail zoom\n",
    "ax2 = axes[1]\n",
    "tail_cut = min(np.percentile(g_pnl, 5), np.percentile(t_pnl, 5))\n",
    "g_tail = g_pnl[g_pnl <= tail_cut]\n",
    "t_tail = t_pnl[t_pnl <= tail_cut]\n",
    "ax2.hist(g_tail, bins=120, density=True, alpha=0.55, color='steelblue',\n",
    "         edgecolor='none', label='Gaussian MC')\n",
    "ax2.hist(t_tail, bins=120, density=True, alpha=0.55, color='#d62728',\n",
    "         edgecolor='none', label=f'Student-t MC (ν={df_t:.1f})')\n",
    "ax2.axvline(-mc_results['es_99'], color='steelblue', lw=2, ls=':',\n",
    "            label=f\"Gauss 99% ES = {mc_results['es_99']:.4%}\")\n",
    "ax2.axvline(-t_results['es_99'], color='#d62728', lw=2, ls=':',\n",
    "            label=f\"t 99% ES = {t_results['es_99']:.4%}\")\n",
    "ax2.set_xlabel('Portfolio Return', fontsize=12)\n",
    "ax2.set_ylabel('Density', fontsize=12)\n",
    "ax2.set_title('Left-Tail Zoom — Fat-Tail Effect', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=9.5, loc='upper left')\n",
    "ax2.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "\n",
    "fig.suptitle('Gaussian vs Student-t Monte Carlo — Impact of Heavy Tails',\n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "fig.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'gaussian_vs_student_t.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()\n",
    "\n",
    "# Quantify the difference\n",
    "print('\\n99% Risk Metric Comparison: Gaussian vs Student-t')\n",
    "print('=' * 55)\n",
    "print(f\"  {'Metric':<20} {'Gaussian':>12} {'Student-t':>12} {'Δ%':>10}\")\n",
    "print(f\"  {'-'*20} {'-'*12} {'-'*12} {'-'*10}\")\n",
    "for label, gkey, tkey in [('VaR 99%', 'var_99', 'var_99'),\n",
    "                           ('ES 99%', 'es_99', 'es_99')]:\n",
    "    g_val = mc_results[gkey]\n",
    "    t_val = t_results[tkey]\n",
    "    pct = (t_val - g_val) / g_val * 100\n",
    "    print(f\"  {label:<20} {g_val:>11.4%} {t_val:>11.4%} {pct:>+9.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707387f",
   "metadata": {},
   "source": [
    "### Observations on the Risk Model Comparison\n",
    "\n",
    "**Key takeaways from the four-model comparison:**\n",
    "\n",
    "1. **Parametric and Gaussian MC agree closely** — both assume Normal returns, so their VaR/ES estimates are similar. The small differences come from estimation noise vs analytical formula.\n",
    "\n",
    "2. **Historical VaR is higher** — the empirical distribution captures fat tails and asymmetries that Gaussian models miss. This is expected: real market returns have excess kurtosis.\n",
    "\n",
    "3. **Student-t MC produces the highest VaR and ES** — by explicitly modelling heavy tails via the fitted $\\nu$ parameter, it assigns more probability to extreme events. The difference between Gaussian and Student-t ES is particularly notable, since ES is a tail-average measure.\n",
    "\n",
    "4. **Basel III implication** — the regulatory shift from VaR to ES was motivated precisely by the fact that VaR ignores loss severity beyond the threshold. The Student-t ES provides a more conservative (and arguably more realistic) estimate of what happens in the worst scenarios."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f4a2cc",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Backtesting\n",
    "\n",
    "### Rolling-Window Methodology\n",
    "\n",
    "- **Window:** 250 trading days (~1 year)\n",
    "- **Method:** Re-estimate μ and Σ at each step, compute 1-day 99% Parametric VaR\n",
    "- **Validation:** Compare forecast to realized loss; record breaches\n",
    "\n",
    "### Kupiec POF Test\n",
    "\n",
    "$$LR = -2\\ln\\left[\\frac{(1-p)^{T-x} \\cdot p^x}{(1-\\hat{p})^{T-x} \\cdot \\hat{p}^x}\\right] \\sim \\chi^2(1)$$\n",
    "\n",
    "$H_0$: The model is correctly specified (observed breach rate = expected breach rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b791d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run full backtest\n",
    "bt_results, breach_stats, kupiec = run_full_backtest(\n",
    "    log_returns, weights, window=250, confidence_level=0.99\n",
    ")\n",
    "\n",
    "print('Breach Statistics')\n",
    "print('=' * 45)\n",
    "for k, v in breach_stats.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f'  {k:.<35} {v:>10.4f}')\n",
    "    else:\n",
    "        print(f'  {k:.<35} {v:>10}')\n",
    "\n",
    "print(f'\\nKupiec POF Test')\n",
    "print('=' * 45)\n",
    "for k, v in kupiec.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f'  {k:.<35} {v:>10.4f}')\n",
    "    else:\n",
    "        print(f'  {k:.<35} {str(v):>10}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141efc9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rolling VaR vs Actual Losses\n",
    "fig, ax = plt.subplots(figsize=(16, 7))\n",
    "\n",
    "dates = bt_results['date']\n",
    "var_line = bt_results['predicted_var']\n",
    "losses = bt_results['actual_loss']\n",
    "breaches = bt_results['breach']\n",
    "\n",
    "ax.plot(dates, losses, color='steelblue', alpha=0.5, lw=0.8, label='Actual Daily Loss')\n",
    "ax.plot(dates, var_line, color='#d62728', lw=1.5, label='99% VaR Forecast')\n",
    "\n",
    "breach_dates = dates[breaches]\n",
    "breach_losses = losses[breaches]\n",
    "ax.scatter(breach_dates, breach_losses, color='#e74c3c', s=30, zorder=5,\n",
    "           label=f'Breaches (n={breaches.sum()})')\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xlabel('Date', fontsize=12)\n",
    "ax.set_ylabel('Loss', fontsize=12)\n",
    "ax.set_title('Rolling 99% VaR Backtest — Predicted vs Actual Losses',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "fig.autofmt_xdate()\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'rolling_var_backtest.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dabf86",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Stress Testing\n",
    "\n",
    "### Scenario 1: Volatility Shock\n",
    "$$\\Sigma_{\\text{shock}} = 2\\Sigma$$\n",
    "\n",
    "Equivalent to doubling all asset volatilities — mimics a sudden market dislocation.\n",
    "\n",
    "### Scenario 2: Correlation Stress\n",
    "$$\\rho_{ij} \\rightarrow 0.9 \\quad \\forall \\, i \\neq j$$\n",
    "\n",
    "Simulates complete diversification collapse under systemic stress — all assets move together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574569ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full stress analysis\n",
    "stress_results = full_stress_analysis(\n",
    "    mu, cov, weights, mc_results, NUM_SIMULATIONS, RANDOM_SEED\n",
    ")\n",
    "\n",
    "print('Volatility Shock Impact (2× Σ)')\n",
    "print('=' * 55)\n",
    "for k, v in stress_results['vol_shock']['impact'].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f'  {k:.<40} {v:>12.4f}')\n",
    "\n",
    "print(f'\\nCorrelation Stress Impact (ρ = 0.9)')\n",
    "print('=' * 55)\n",
    "for k, v in stress_results['corr_stress']['impact'].items():\n",
    "    if isinstance(v, float):\n",
    "        print(f'  {k:.<40} {v:>12.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc890da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stress comparison chart\n",
    "fig, ax = plt.subplots(figsize=(12, 7))\n",
    "\n",
    "metrics_keys = ['var_95', 'var_99', 'es_95', 'es_99']\n",
    "labels = ['95% VaR', '99% VaR', '95% ES', '99% ES']\n",
    "x = np.arange(len(metrics_keys))\n",
    "width = 0.25\n",
    "\n",
    "base_vals = [mc_metrics[f'mc_{m}'] for m in metrics_keys]\n",
    "vol_vals = [stress_results['vol_shock']['results'][m] for m in metrics_keys]\n",
    "corr_vals = [stress_results['corr_stress']['results'][m] for m in metrics_keys]\n",
    "\n",
    "ax.bar(x - width, base_vals, width, label='Baseline', color='steelblue', alpha=0.8)\n",
    "ax.bar(x, vol_vals, width, label='Vol Shock (2×)', color='#d62728', alpha=0.8)\n",
    "ax.bar(x + width, corr_vals, width, label='Corr Stress (ρ=0.9)', color='#9467bd', alpha=0.8)\n",
    "\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1.0))\n",
    "ax.set_xlabel('Risk Metric', fontsize=12)\n",
    "ax.set_ylabel('Value', fontsize=12)\n",
    "ax.set_title('Stress Test Comparison — Risk Metric Sensitivity',\n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, fontsize=11)\n",
    "ax.legend(fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.savefig(PROJECT_ROOT / 'results' / 'figures' / 'stress_comparison.png',\n",
    "            dpi=150, bbox_inches='tight', facecolor='white')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ce0724",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Model Limitations\n",
    "\n",
    "| Limitation | Impact | Status |\n",
    "|-----------|--------|--------|\n",
    "| **Gaussian tails too thin** | Underestimates tail risk | ✅ **Addressed** — Student-t MC captures heavy tails |\n",
    "| **Static correlation** | Misses regime-dependent correlation | ⬜ Future: DCC-GARCH or regime-switching |\n",
    "| **No liquidity effects** | Overstates ability to exit positions | ⬜ Future: Liquidity-adjusted VaR |\n",
    "| **No regime switching** | Misses volatility clustering | ⬜ Future: GARCH conditional volatility |\n",
    "| **Single-period horizon** | √t scaling assumes i.i.d. | ⬜ Future: Multi-step MC simulation |\n",
    "| **Linear portfolio** | Cannot handle options/derivatives | ⬜ Future: Delta-gamma or full revaluation |\n",
    "\n",
    "The Student-t extension directly addresses the most impactful limitation (Gaussian underestimation of tail risk). The remaining items are standard trade-offs in first-generation desk-level risk models. Production systems at major institutions address these through more sophisticated statistical frameworks (DCC-GARCH, EVT, filtered historical simulation)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b33157",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Methodology Summary\n",
    "\n",
    "### Algorithm Pipeline\n",
    "\n",
    "```\n",
    "Historical Prices\n",
    "    │\n",
    "    ▼\n",
    "Log Returns (r_t = ln(P_t / P_{t-1}))\n",
    "    │\n",
    "    ├──→ Mean Vector (μ)\n",
    "    ├──→ Covariance Matrix (Σ)\n",
    "    │\n",
    "    ├──→ Historical VaR (empirical quantile)\n",
    "    ├──→ Parametric VaR (z_α · σ_p - μ_p)\n",
    "    ├──→ Gaussian Monte Carlo VaR\n",
    "    │       ├── Cholesky: Σ = L L^T\n",
    "    │       ├── Z ~ N(0, I)\n",
    "    │       ├── R = μ + L Z\n",
    "    │       └── VaR, ES from quantiles\n",
    "    │\n",
    "    └──→ Student-t Monte Carlo VaR\n",
    "            ├── Fit ν via MLE\n",
    "            ├── Z ~ t(ν), rescale: Z̃ = Z·√((ν-2)/ν)\n",
    "            ├── R = μ + L Z̃\n",
    "            └── VaR, ES from quantiles\n",
    "                    │\n",
    "                    ├──→ Backtesting (250-day rolling, Kupiec test)\n",
    "                    └──→ Stress Testing (vol shock, corr stress)\n",
    "```\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "1. Log returns are stationary and ergodic\n",
    "2. Historical covariance is a reasonable estimator of future risk\n",
    "3. Portfolio is linear (no optionality)\n",
    "4. Positions can be liquidated at market prices within 1 trading day\n",
    "5. No transaction costs or market impact\n",
    "6. Student-t degrees of freedom are stable over the sample period\n",
    "\n",
    "---\n",
    "\n",
    "*Report generated by Monte Carlo Market Risk Engine v2.0 — includes Student-t heavy-tailed extension*"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
